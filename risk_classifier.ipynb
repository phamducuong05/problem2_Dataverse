{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54582de6-a9c9-4197-82f9-4cde1117fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "_HAS_XGB, _HAS_CAT = False, False\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    _HAS_XGB = True\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    _HAS_CAT = True\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f637af3c-e60e-4996-a266-4620c61f9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models():\n",
    "    models = {\n",
    "        \"rf\": RandomForestClassifier(n_estimators=400, min_samples_leaf=2, random_state=42, n_jobs=-1),\n",
    "        \"extratrees\": ExtraTreesClassifier(n_estimators=600, min_samples_leaf=2, random_state=42, n_jobs=-1),\n",
    "        \"gbt\": GradientBoostingClassifier(random_state=42),\n",
    "        \"svm\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "        \"logreg\": LogisticRegression(max_iter=5000, solver=\"lbfgs\"),\n",
    "    }\n",
    "    if _HAS_XGB:\n",
    "        models[\"xgb\"] = XGBClassifier(\n",
    "            n_estimators=800, max_depth=6, learning_rate=0.05,\n",
    "            subsample=0.9, colsample_bytree=0.9, objective=\"multi:softprob\",\n",
    "            tree_method=\"hist\", random_state=42, n_jobs=-1\n",
    "        )\n",
    "    if _HAS_CAT:\n",
    "        models[\"catboost\"] = CatBoostClassifier(\n",
    "            iterations=800, depth=8, learning_rate=0.05,\n",
    "            loss_function=\"MultiClass\", random_seed=42, verbose=100\n",
    "        )\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40730bd3-aced-4a61-b264-c9139c8fd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_volatility_and_numeric_label(df: pd.DataFrame, vol_window: int = 21) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if \"return\" not in df.columns or df[\"return\"].isna().all():\n",
    "        df[\"return\"] = df.groupby(\"ticker\")[\"close\"].pct_change()\n",
    "    df[\"volatility\"] = df.groupby(\"ticker\")[\"return\"].transform(\n",
    "        lambda s: s.rolling(vol_window).std() * np.sqrt(252)\n",
    "    )\n",
    "    sub = df.dropna(subset=[\"volatility\"])\n",
    "    if sub.empty:\n",
    "        raise ValueError(\"Không có dữ liệu đủ để tính volatility.\")\n",
    "    q = sub[\"volatility\"].quantile([0.33, 0.66])\n",
    "    q33, q66 = q.loc[0.33], q.loc[0.66]\n",
    "    df[\"risk_label\"] = np.select(\n",
    "        [\n",
    "            (df[\"volatility\"] > q66),\n",
    "            (df[\"volatility\"] <= q66) & (df[\"volatility\"] > q33),\n",
    "            (df[\"volatility\"] <= q33),\n",
    "        ],\n",
    "        [2, 1, 0],\n",
    "        default=1\n",
    "    ).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f3c514-ee1d-4421-8f45-ed073a654ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"open\",\"high\",\"low\",\"close\",\"volume\",\n",
    "    \"ema_50\",\"ema_200\",\"ema_gap\",\n",
    "    \"macd\",\"macd_signal\",\"macd_diff\",\n",
    "    \"rsi\",\"mfi\",\n",
    "    \"bollinger_hband\",\"bollinger_lband\",\"bollinger_pct\",\n",
    "    \"return\"\n",
    "]\n",
    "EXCLUDE_IF_PRESENT = [\"volatility\",\"bollinger_bw\",\"golden_cross\",\"death_cross\",\"macd_cross\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31aaba8d-906d-4367-b07f-c6f5b296a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_raw(file_path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(file_path)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    must_cols = [\"ticker\",\"timestamp\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "    missing = [c for c in must_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Thiếu cột trong Excel: {missing}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"timestamp\"])\n",
    "    for col in [\"open\",\"high\",\"low\",\"close\",\"volume\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df[(df[\"close\"] > 0) & (df[\"volume\"] >= 0)].copy()\n",
    "    df = df.sort_values([\"ticker\",\"timestamp\"]).reset_index(drop=True)\n",
    "    return df\n",
    "def finalize_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"ema_50\" in df.columns and \"ema_200\" in df.columns and \"ema_gap\" not in df.columns:\n",
    "        denom = df[\"ema_200\"].replace(0, np.nan)\n",
    "        df[\"ema_gap\"] = (df[\"ema_50\"] - df[\"ema_200\"]) / denom\n",
    "\n",
    "    for col in [\"mfi\",\"bollinger_pct\",\"macd\",\"macd_signal\",\"macd_diff\",\"rsi\",\n",
    "                \"ema_50\",\"ema_200\",\"bollinger_hband\",\"bollinger_lband\",\"return\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99dc39bc-cac7-4ebc-9602-a486285c523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEST_SIZE = 0.2\n",
    "DEFAULT_RANDOM_STATE = 42\n",
    "def run_all_models_and_compare(file_path: str, model_dir: str, test_size: float = DEFAULT_TEST_SIZE,\n",
    "                               random_state: int = DEFAULT_RANDOM_STATE) -> pd.DataFrame:\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    df = load_excel_raw(file_path)\n",
    "    df = finalize_features(df)\n",
    "    df = add_volatility_and_numeric_label(df)\n",
    "    feats = [f for f in FEATURES if f in df.columns and f not in EXCLUDE_IF_PRESENT]\n",
    "    if not feats:\n",
    "        raise ValueError(\"Không còn feature nào hợp lệ sau khi loại proxy volatility/cross.\")\n",
    "    df_xy = df.dropna(subset=feats + [\"risk_label\"]).copy()\n",
    "    X = df_xy[feats]\n",
    "    y = df_xy[\"risk_label\"].astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    results = []\n",
    "    models = make_models()\n",
    "    print(f\"Using features ({len(feats)}): {feats}\")\n",
    "    for name, model in models.items():\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"MODEL: {name}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "        bundle = {\"model\": model, \"features\": feats, \"model_name\": name, \"label_mode\": \"numeric_0_1_2\"}\n",
    "        save_path = os.path.join(model_dir, f\"risk_model_{name}.pkl\")\n",
    "        joblib.dump(bundle, save_path)\n",
    "        print(f\"[Saved] {save_path}\")\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"test_acc\": accuracy_score(y_test, y_pred),\n",
    "            \"test_macro_f1\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "            \"test_size\": len(y_test)\n",
    "        })\n",
    "    res_df = pd.DataFrame(results).sort_values(\"test_macro_f1\", ascending=False).reset_index(drop=True)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BẢNG SO SÁNH (sắp theo Macro-F1 giảm dần)\")\n",
    "    print(\"=\"*80)\n",
    "    print(res_df.to_string(index=False))\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a150bd1a-9556-434f-993d-4df99ad20b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features (17): ['open', 'high', 'low', 'close', 'volume', 'ema_50', 'ema_200', 'ema_gap', 'macd', 'macd_signal', 'macd_diff', 'rsi', 'mfi', 'bollinger_hband', 'bollinger_lband', 'bollinger_pct', 'return']\n",
      "\n",
      "================================================================================\n",
      "MODEL: rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9381    0.9273    0.9327      1927\n",
      "           1     0.8785    0.8937    0.8860      2127\n",
      "           2     0.9381    0.9310    0.9345      1986\n",
      "\n",
      "    accuracy                         0.9167      6040\n",
      "   macro avg     0.9182    0.9174    0.9178      6040\n",
      "weighted avg     0.9171    0.9167    0.9169      6040\n",
      "\n",
      "[Saved] model_output\\risk_model_rf.pkl\n",
      "\n",
      "================================================================================\n",
      "MODEL: extratrees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9450    0.9455    0.9453      1927\n",
      "           1     0.9016    0.9088    0.9052      2127\n",
      "           2     0.9517    0.9431    0.9474      1986\n",
      "\n",
      "    accuracy                         0.9318      6040\n",
      "   macro avg     0.9328    0.9325    0.9326      6040\n",
      "weighted avg     0.9319    0.9318    0.9318      6040\n",
      "\n",
      "[Saved] model_output\\risk_model_extratrees.pkl\n",
      "\n",
      "================================================================================\n",
      "MODEL: gbt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7794    0.8194    0.7989      1927\n",
      "           1     0.6788    0.6827    0.6807      2127\n",
      "           2     0.8352    0.7885    0.8112      1986\n",
      "\n",
      "    accuracy                         0.7611      6040\n",
      "   macro avg     0.7645    0.7635    0.7636      6040\n",
      "weighted avg     0.7623    0.7611    0.7613      6040\n",
      "\n",
      "[Saved] model_output\\risk_model_gbt.pkl\n",
      "\n",
      "================================================================================\n",
      "MODEL: svm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6336    0.3311    0.4349      1927\n",
      "           1     0.3687    0.5275    0.4340      2127\n",
      "           2     0.4543    0.4552    0.4547      1986\n",
      "\n",
      "    accuracy                         0.4411      6040\n",
      "   macro avg     0.4855    0.4379    0.4412      6040\n",
      "weighted avg     0.4813    0.4411    0.4411      6040\n",
      "\n",
      "[Saved] model_output\\risk_model_svm.pkl\n",
      "\n",
      "================================================================================\n",
      "MODEL: logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7849    0.7592    0.7718      1927\n",
      "           1     0.6059    0.6201    0.6129      2127\n",
      "           2     0.7744    0.7795    0.7769      1986\n",
      "\n",
      "    accuracy                         0.7169      6040\n",
      "   macro avg     0.7217    0.7196    0.7206      6040\n",
      "weighted avg     0.7184    0.7169    0.7175      6040\n",
      "\n",
      "[Saved] model_output\\risk_model_logreg.pkl\n",
      "\n",
      "================================================================================\n",
      "BẢNG SO SÁNH (sắp theo Macro-F1 giảm dần)\n",
      "================================================================================\n",
      "     model  test_acc  test_macro_f1  test_size\n",
      "extratrees  0.931788       0.932612       6040\n",
      "        rf  0.916722       0.917753       6040\n",
      "       gbt  0.761093       0.763602       6040\n",
      "    logreg  0.716887       0.720553       6040\n",
      "       svm  0.441060       0.441224       6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=5000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = r'D:\\Downloads\\DSTC vòng 2\\cleaned data\\UPCOM_cleaned_last.xlsx'\n",
    "    model_dir = 'model_output'\n",
    "    results = run_all_models_and_compare(file_path, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8506a-5ea1-4d0b-b6b8-ce591175147d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
